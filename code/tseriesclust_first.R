tseriesclust_first <-
function(data,maxiter=1000,burnin=floor(0.1*maxiter),thinning=5,scale=TRUE,
            frequency=52,seasonfreq=2,seasondelay=12,
           level=FALSE,trend=TRUE,seasonality=TRUE,deg=2,c0eps=2,c1eps=1,
           c0beta=2,c1beta=1,c0alpha=2,c1alpha=1,priora=TRUE,pia=0.5,
           q0a=1,q1a=1,priorb=TRUE,q0b=1,q1b=1,a=0.25,b=0,seed=42){
 
  set.seed(seed)
  # IN:
  #
  # data    <- Data frame with the time series information. 
  # maxiter <- Maximum number of iterations for Gibbs sampling.Default value = 1000.
  # burnin  <- Burn-in period of the Markov Chain generated by Gibbs sampling. 
  # thinning <- Number that indicates how many Gibbs sampling simulations should be skipped to form the Markov Chain.
  # scale   <- Flag that indicates if the time series data should be scaled. If TRUE, then the time series are scaled to the [0,1] interval. 
  # frequency <- Number that indicates the frequency of data in a year, e.g. 12 means one value each month.
  # seasonfreq <- Number that indicates the frequency in a year of season component, e.g. 12 means we consider months as seasonality 
  # seasondelay <- After how many data begins the first season (useful for example for dividing spring and summer from winter and autumn)
  # level   <- Flag that indicates if the level of the time series will be considered for clustering. If TRUE, then it is taken into account.
  # trend   <- Flag that indicates if the polinomial trend of the model will be considered for clustering. If TRUE, then it is taken into account. 
  # seasonality <- Flag that indicates if the seasonal components of the model will be considered for clustering. If TRUE, then they are taken into account.
  # deg     <- Degree of the polinomial tendency of the model. Default value = 2. 
  # c0eps   <- Shape parameter of the hyper-prior distribution on sig2eps. Default value = 2.
  # c1eps   <- Rate parameter of the hyper-prior distribution on sig2eps. Default value = 1.
  # c0beta  <- Shape parameter of the hyper-prior distribution on sig2beta. Default value = 2.
  # c1beta  <- Rate parameter of the hyper-prior distribution on sig2beta. Default value = 1.
  # c0alpha <- Shape parameter of the hyper-prior distribution on sig2alpha. Default value = 2.
  # c1alpha <- Rate parameter of the hyper-prior distribution on sig2alpha. Default value = 1.
  # priora  <- Flag that indicates if a prior on parameter "a" is to be assigned. If TRUE, a prior on "a" is assigned.
  # pia     <- Mixing proportion of the prior distribution on parameter "a". Default value = 0.5.
  # q0a     <- Shape parameter of the continuous part of the prior distribution on parameter "a". Default value = 1.
  # q1a     <- Shape parameter of the continuous part of the prior distribution on parameter "a". Default value = 1.
  # priorb  <- Flag that indicates if a prior on parameter "b" is to be assigned. If TRUE, a prior on "b" is assigned. Default value = FALSE.
  # q0b     <- Shape parameter of the prior distribution on parameter "b". Default value = 1.
  # q1b     <- Shape parameter of the prior distribution on parameter "b". Default value = 1.
  # a       <- Initial/fixed value of parameter "a". Default value = 0.25.
  # b       <- Initial/fixed value of parameter "b". Default value = 0.
 
  # OUT:
  #
  # memorygn        <- CL*n matrix where [k,i]=[k,j] if i and j belong to the same cluster at iteration k.
  # arrho   <- Acceptance rate of the parameter "rho".
  # ara     <- Acceptance rate of the parameter "a".
  # arb     <- Acceptance rate of the parameter "b".
  # sig2epssample <- Matrix that in its columns contains the sample of each sig2eps_i's posterior distribution after Gibbs sampling.
  # sig2alphasample <- Matrix that in its columns contains the sample of each sig2alpha_i's posterior distribution after Gibbs sampling.
  # sig2betasample <- Matrix that in its columns contains the sample of each sig2beta_i's posterior distribution after Gibbs sampling.
  # sig2thesample <- Vector that contains the sample of sig2the's posterior distribution after Gibbs sampling. 
  # rhosample <- Vector that contains the sample of rho's posterior distribution after Gibbs sampling.
  # asample <- Vector that contains the sample of a's posterior distribution after Gibbs sampling.
  # bsample <- Vector that contains the sample of b's posterior distribution after Gibbs sampling.
  # msample <- Vector that contains the sample of the number of groups at each Gibbs sampling iteration.

  
  data <- scaleandperiods(data,scale)  
  mydata <- as.matrix(data$mydata)              # Matrix with the scaled data.
  periods <- data$periods            # Array with the data periods.
  cts <- data$cts                    # Variable that indicates if any time series
                                     # were removed from the original data set because they were constant.
  
  ##### CONSTRUCTION OF THE DESIGN MATRICES #####
  
  T <- nrow(mydata)                        # Number of periods of the time series
  n <- ncol(mydata)                        # Number of time series present in the data
  #Construction of the design matrices Z and X of the linear model, where we take into account the seasonality of the data
  #and the degree of the polynomial trend
  DM <- designmatrices(deg,T,frequency,seasonfreq,seasondelay,mod=FALSE)
  p <- DM$p
  d <- DM$d
  Z <- DM$Z
  X <- DM$X
  
  
  ##### INITIAL VALUES FOR THE PARAMETERS THAT WILL BE PART OF THE GIBBS SAMPLING #####
  
  sig2eps <- matrix(1,n,1)                        # Vector that has the diagonal entries of the variance-covariance matrix for every epsilon_i.
  sig2the <- 1    # Initial value for sig2the.
  rho <- 0        # Initial value for rho.  
  
  P <- matrix(0,T,T)             # Initial matrix P.                        
  
  for (j in seq(T)){
    for (k in seq(T)){
      P[j,k] <- rho^(abs(j-k))  
    }
  }
  
  R <- sig2the*P                 # Initial matrix R.
  
  
    sig2beta <- matrix(1,d,1)                       # Vector that has the diagonal entries of the variance-covariance matrix for beta. 
    sigmabeta <- diag(c(sig2beta),d,d)              # Variance-covariance matrix for beta.
    invsigmabeta <- diag(1/c(sig2beta),d,d)         # Inverse variance-covariance matrix for beta.
    sig2alpha <- matrix(1,p,1)                      # Vector that has the diagonal entries of the variance-covariance matrix for alpha.
    sigmaalpha <- diag(c(sig2alpha),p,p)            # Variance-covariance matrix for alpha.
    invsigmaalpha <- diag(1/c(sig2alpha),p,p)       # Inverse variance-covariance matrix for alpha.
    
    alpha <- matrix(mvrnorm(n,matrix(0,p,1),sigmaalpha),p,n)  # alpha is a matrix with a vector value of alpha for every time series in its columns. 
    beta <- matrix(mvrnorm(n,matrix(0,d,1),sigmabeta),d,n)    # beta is a matrix with a vector value of beta for every time series in its columns.
    theta <- matrix(mvrnorm(n,matrix(0,T,1),R),T,n)           # theta is a matrix with a vector value of theta for every time series in its columns.
    gamma <- rbind(beta,theta)                                # gamma is the union by rows of the beta and theta matrices.  
  
  
  
  iter <- 0                                    # Counter for each Gibbs sampling iteration.
  iter1 <- 0                                   # Counter for the number of iterations saved during the Gibbs sampling.
  arrho <- 0                                   # Variable that will contain the acceptance rate of rho in the Metropolis-Hastings step.
  ara <- 0                                     # Variable that will contain the acceptance rate of a in the Metropolis-Hastings step.
  arb <- 0                                     # Variable that will contain the acceptance rate of b in the Metropolis-Hastings step.
  sim <- matrix(0,n,n)                         # Initialization of the similarities matrix.
  
  if(thinning == 0){
    CL <- floor(maxiter-burnin)
  }else{
    CL <- floor((maxiter-burnin)/thinning)
  }
  
  memory <- matrix(0,CL*n,n)   # Matrix that will contain the cluster configuration of every iteration that is saved during the Gibbs sampling.
  memorygn <- matrix(0,CL,n)   # Matrix that will save the group number to which each time series belongs in every iteration saved.  
  sig2epssample <- matrix(0,CL,n)   # Matrix that in its columns will contain the sample of each sig2eps_i's posterior distribution after Gibbs sampling.
  sig2thesample <- matrix(0,CL,1)   # Vector that will contain the sample of sig2the's posterior distribution after Gibbs sampling. 
  rhosample <- matrix(0,CL,1)       # Vector that will contain the sample of rho's posterior distribution after Gibbs sampling.
  asample <- matrix(0,CL,1)         # Vector that will contain the sample of a's posterior distribution after Gibbs sampling.
  bsample <- matrix(0,CL,1)         # Vector that will contain the sample of b's posterior distribution after Gibbs sampling.
  msample <- matrix(0,CL,1)         # Vector that will contain the sample of the number of groups at each Gibbs sampling iteration.
  
 
  sig2alphasample <- matrix(0,CL,p) # Matrix that in its columns will contain the sample of each sig2alpha_i's posterior distribution after Gibbs sampling.
  sig2betasample <- matrix(0,CL,d)  # Matrix that in its columns will contain the sample of each sig2beta_i's posterior distribution after Gibbs sampling. 
  
  
  
  ##### BEGINNING OF GIBBS SAMPLING #####
  
  while(iter < maxiter){
    
    ##### 1) SIMULATION OF ALPHA'S POSTERIOR DISTRIBUTION #####
    
        for(i in 1:n){
          sigmaeps <- diag(c(sig2eps[i]),T)
          Q <- sigmaeps + R
          Qinv <- chol2inv(chol(Q))
          Vinv <- t(X) %*% Qinv %*% X + invsigmabeta
          V <- chol2inv(chol(Vinv))
          
          Winv <- Qinv + (Qinv %*% X %*% V %*% t(X) %*% Qinv)
          W <- chol2inv(chol(Winv))
          Valphainv <- (t(Z) %*% Winv %*% Z) + invsigmaalpha
          Valpha <- chol2inv(chol(Valphainv))
          
          mualpha <- Valpha %*% t(Z) %*% Winv %*% mydata[,i]
          
          alpha[,i] <- mvrnorm(1,mualpha,Valpha)
        }
    
    
    ##### 2) SIMULATION OF GAMMA'S = (BETA,THETA) POSTERIOR DISTRIBUTION #####
    
    
    for(i in 1:n){
      # Only the first entries of gamma[,-i] are compared to determine the cluster configuration
      # comp11 is a function that computes the distinct observations and frequencies in a numeric vector.
      gr <- comp11(gamma[1,-i])                         
      jstar <- gr$jstar                                 # Object that contains the positions of the unique vectors in gamma[,-i]
      gmi <- gamma[,-i]                                 # Matrix with all the elements of gamma, except for the i-th element
      gammastar <- as.matrix(gmi[,jstar])               # Matrix with the unique vectors in gamma(-i)
      mi <- gr$rstar                                    # Number of unique vectors in gamma(-i) (Number of groups)
      nstar <- gr$nstar                                 # Frequency of each unique vector in gamma(-i)
      
        if(d == 1){
          betastar <- t(as.matrix(gammastar[1:d,]))
          thetastar <- as.matrix(gammastar[(d+1):(T+d),]) 
        }else{
          betastar <- as.matrix(gammastar[1:d,])            # Separation of unique vectors between betastar and thetastar
          thetastar <- as.matrix(gammastar[(d+1):(T+d),])    
        }     
      
      
      # Matrices necessary for the following steps
      sigmaeps <- sig2eps[i]*diag(1,T)
      invsigmaeps <- (1/sig2eps[i])*diag(1,T)
      Q <- sigmaeps + R
      Qinv <- chol2inv(chol(Q))
      Vinv <- t(X) %*% Qinv %*% X + invsigmabeta
      V <- chol2inv(chol(Vinv))
      Winv <- Qinv + (Qinv %*% X %*% V %*% t(X) %*% Qinv)
      W <- chol2inv(chol(Winv))        
      
      
      
      # Computing weigths for gamma(i)'s posterior distribution
      
     
        dj <- matrix(0,mi,1)
        d0 <- (b + a*mi)*dmvnorm(mydata[,i],(Z %*% alpha[,i]),W)
        
        den <- 0
        
        for(j in 1:mi){
          dj[j] <- (nstar[j] - a)*dmvnorm(mydata[,i],(Z %*% alpha[,i] + X %*% betastar[,j] + thetastar[,j]),sigmaeps)
        }
        
        den <- d0 + sum(dj)
        if(den == 0){
          d0 <- log(b + a*mi) + dmvnorm(mydata[,i],(Z %*% alpha[,i]),W,log=TRUE)
          for(j in 1:mi){
            dj[j] <- log(nstar[j] - a) + dmvnorm(mydata[,i],(Z %*% alpha[,i] + X %*% betastar[,j] + thetastar[,j]),sigmaeps,log=TRUE)          
          }
          dj <- rbind(dj,d0)
          aa <- min(dj)
          q <- (1+(dj-aa)+(dj-aa)^2/2)/sum(1+(dj-aa)+(dj-aa)^2/2)
        }else{
          q <- dj/den
          q <- rbind(q,d0/den)
        }
      
      
      # Sampling a number between 1 and (mi+1) to determine what will be the simulated value for gamma(i)
      # The probabilities of the sample are based on the weights previously computed
      
      y <- sample((1:(mi+1)), size=1, prob = q)
      
      # If sample returns the value (mi+1), a new vector from g0 will be simulated and assigned to gamma(i)
      
      if (y == mi+1){
    
          Sthetai <- chol2inv(chol(invsigmaeps + chol2inv(chol(R))))
          muthetai <- Sthetai %*% invsigmaeps %*% (mydata[,i] - (Z %*% alpha[,i]) - (X %*% beta[,i]))
          mubetai <- V %*% t(X) %*% Qinv %*% (mydata[,i] - (Z %*% alpha[,i]))
          beta0 <- matrix(mvrnorm(1,mubetai,V),d,1)
          theta0 <- matrix(mvrnorm(1,muthetai,Sthetai),T,1)
          gamma[,i] <- rbind(beta0,theta0)
              
      } else{
        gamma[,i] = gammastar[,y]                     # Otherwise, column y from gammastar will be assigned to gamma(i)
      }
      
    }
    
    ####### 2.1) LABEL ASSIGNMENT #####
    # Computation of all latent classes of the gamma vectors after the simulation of their posterior distribution.
    # comp11 is a function that computes the distinct observations and frequencies in a numeric vector.
    gr <- comp11(gamma[1,])                   
    jstar <- gr$jstar
    gammastar <- as.matrix(gamma[,jstar])     # Unique values of the gamma vectors. 
    m <- gr$rstar                             # Total number of latent classes (groups).
    nstar <- gr$nstar                         # Frequency of each latent class (group).
    gn <- gr$gn                               # Identifier of the group to which each time series belongs.
    
    
    
    
    ##### 6) SIMULATION OF SIG2THE'S POSTERIOR DISTRIBUTION #####
    
    cholP <- chol(P)              # Calculation of the Cholesky factorization of P.
    Pinv <- chol2inv(cholP)       # Obtaining the inverse of P. 
    s1 <- 0
    
    # Calculating the sum necessary for the rate parameter of the posterior distribution.
    for(j in 1:(m-1)){
      s1 <- s1 + t(as.matrix(thetastar[,j])) %*% Pinv %*% as.matrix(thetastar[,j])
    }
    
    sig2the <- 1/rgamma(1,(m*T/2),(s1/2))
    
    
    ##### 7) SIMULATION OF RHO'S POSTERIOR DISTRIBUTION (Metropolis-Hastings step) #####
    
    rhomh <- runif(1,-1,1)            # Sampling from the proposal distribution.
    
    Pmh <- matrix(0,T,T)
    
    # Calculating the matrix P for the proposed value rhomh.
    for (j in 1:T){
      for (k in 1:T){
        Pmh[j,k] <- rhomh^(abs(j-k))  
      }
    }
    
    cholPmh <- chol(Pmh)              # Calculating the Cholesky factor of Pmh.
    Pmhinv <- chol2inv(cholPmh)       # Obtaining the inverse from Pmh
    s <- 0
    
    # Calculating the sum necessary for the computation of the acceptance probability.
    for(j in 1:(m-1)){
      s <- s + t(as.matrix(thetastar[,j])) %*% (Pmhinv-Pinv) %*% as.matrix(thetastar[,j])
    }
    
    # Computation of the acceptance probability.
    q <- (-m/2)*(log(prod(diag(cholPmh)))- log(prod(diag(cholP)))) - ((1/(2*sig2the))*s) + (1/2)*(log(1 + rhomh*rhomh) - log(1 + rho*rho)) - log(1 - rhomh*rhomh) + log(1 - rho*rho) 
    
    # Definition of the acceptance probability. 
    quot <- min(0,q)
    
    # Sampling a uniform random variable in [0,1] to determine if the proposal is accepted or not.
    unif1 <- runif(1,0,1)
    
    # Acceptance step.
    if(log(unif1) <= quot){
      rho <- rhomh
      arrho <- arrho + 1
      
      for (j in seq(T)){
        for (k in seq(T)){
          P[j,k] <- rho^(abs(j-k))  
        }
      }
      
    }
    
    R <- sig2the*P  
    
    
    ##### 3) SIMULATION OF SIG2EPS' POSTERIOR DISTRIBUTION #####
    
   
    M <- t(mydata - Z%*%alpha - X%*%beta - theta) %*% (mydata - Z%*%alpha - X%*%beta - theta)
    
    
    sig2eps <- 1/rgamma(n,(c0eps + T/2),(c1eps + diag(M)/2))
    
    
    ##### 4) SIMULATION OF SIMGAALPHA'S POSTERIOR DISTRIBUTION #####
    
   
    sig2alpha <- 1/rgamma(p,(c0alpha + n/2),(c1alpha + rowSums(alpha^2)))
      
    sigmaalpha <- diag(c(sig2alpha),p,p)
    invsigmaalpha <- diag(1/c(sig2alpha),p,p) 
    
    
    
    ##### 5) SIMULATION OF SIGMABETA'S POSTERIOR DISTRIBUTION #####
    
    
    sig2beta <- 1/rgamma(d,(c0beta + m/2),(c1beta + colSums(betastar^2)/2))
      
    sigmabeta <- diag(c(sig2beta),d,d)
    invsigmabeta <- diag(1/c(sig2beta),d,d) 
    
    
    
    ##### 8) SIMULATION OF A'S POSTERIOR DISTRIBUTION (METROPOLIS-HASTINGS WITH UNIFORM PROPOSALS) #####
    
    if(priora == 1){
      
      if (b < 0){
        amh <- runif(1,-b,1)  
      } else{
        unif2 <- runif(1,0,1)
        if (unif2 <= 0.5){
          amh <- 0
        } else{
          amh <- runif(1,0,1) 
        }
      }
      
      # If b is not greater than -a, then accept the proposal directly.
      if ((a+b) <= 0){
        a <- amh
      } else{
        
        quot1 <- 0
        
        if(m > 1){
          for (j in 1:(m-1)){
            quot1 <- quot1 + log(b + j*amh) + log(gamma(nstar[j] - amh)) - log(gamma(1 - amh)) - log(b + j*a) - log(gamma(nstar[j] - a)) + log(gamma(1 - a))
          }
        }
        
        quot1 <- quot1 + log(gamma((nstar[m] - amh))) - log(gamma(1 - amh)) - log(gamma((nstar[m] - a))) + log(gamma(1 - a))
        
        if (a == 0){
          fa <- 0.5 
        } else{
          fa <- 0.5*dbeta(a,q0a,q1a) 
        }
        
        if (amh == 0){
          famh <- 0.5
        } else{
          famh <- 0.5*dbeta(amh,q0a,q1a)
        }
        
        # Quotient to evaluate the Metropolis-Hastings step in logs    
        quot1 <- quot1 + log(famh) - log(fa)
        
        # Determination of the probability for the Metropolis-Hastings step
        alphamh1 <- min(quot1,0)
        
        unif3 <- runif(1,0,1)
        
        # Acceptance step
        if (log(unif3) <= alphamh1){
          a <- amh
          ara <- ara + 1
        }
        
      }
      
    }
    
    
    ##### 9) SIMULATION OF B'S POSTERIOR DISTRIBUTION (METROPOLIS-HASTINGS WITH GAMMA PROPOSALS) #####
    
    if(priorb == 1){
      
      y1 <- rgamma(1,1,0.1)
      bmh <- y1 - a
      
      # If b is not greater than -a, then accept the proposal directly.
      if ((a+b) <= 0){
        b <- bmh  
      } else{
        
        quot2 <- 0
        
        if(m > 1){
          for (j in 1:(m-1)){
            quot2 <- quot2 + log(bmh + j*a) - log(b + j*a)
          }
        }
        
        fb <- dgamma(a+b,q0b,q1b)      
        fbmh <- dgamma(y1,q0b,q1b)
        
        # Quotient to evaluate the Metropolis-Hastings step in logs
        quot2 <- quot2 + (log(gamma(bmh+1)) - log(gamma(bmh+n)) - log(gamma(b+1)) + log(gamma(b+n))) + (log(fbmh) - log(fb)) - 0.1*(b - bmh)
        
        # Determination of the probability for the Metropolis-Hastings step
        alphamh2 <- min(quot2,0)
        
        unif4 <- runif(1,0,1)
        
        # Acceptance step
        if (log(unif4) <= alphamh2){
          b <- bmh
          arb <- arb + 1
        }
        
      }
      
    }
    
    
    if((iter %% thinning) == 0 & iter >= burnin){
      iter1 <- iter1 + 1
      sig2epssample[iter1,] <- sig2eps
      sig2thesample[iter1] <- sig2the
      rhosample[iter1] <- rho
      asample[iter1] <- a
      bsample[iter1] <- b
      msample[iter1] <- m
      memorygn[iter1,] <- gn
 
      sig2alphasample[iter1,] <- sig2alpha
      sig2betasample[iter1,] <- sig2beta
      
    }
    
    iter <- iter + 1
    if(iter %% 1 == 0){
      cat("Iteration Number: ",iter,". Progress: ",(iter/maxiter)*100,"%","\n") 
    }
    
  }
  
  ##### END OF GIBBS SAMPLING #####
  
  # Calculation of acceptance rates and similarities matrix
  arrho <- arrho/iter
  ara <- ara/iter
  arb <- arb/iter
  sim <- sim/iter1
  
  
  
  return(list(arrho = arrho,ara = ara,arb = arb,memorygn=memorygn,
              sig2epssample = sig2epssample,sig2alphasample = sig2alphasample,
              sig2betasample = sig2betasample,sig2thesample = sig2thesample,rhosample = rhosample,
              asample = asample,bsample = bsample,msample = msample,periods = periods,scale=scale))
   
}
